{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qC71Qv1-TtI-"
   },
   "source": [
    "\n",
    "Solution template for the question 1.6-1.7. This template consists of following steps. Except the step 2, you don't need to modify it to answer the questions.\n",
    "1.   Initialize libraries\n",
    "2.   **Insert the answers for the questions 1.1~1.5 below (this is the part you need to fill)**\n",
    "3.   Define data loaders\n",
    "4.   Define VAE network architecture\n",
    "5.   Initialize the model and optimizer\n",
    "6.   Train the model\n",
    "7.   Save the model\n",
    "8.   Load the model\n",
    "9.   Evaluate the model with importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcs7QFvETxQJ"
   },
   "source": [
    "Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLoP5GRpEPbI"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from torchvision.datasets import utils\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.modules import upsampling\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTB40neeR6-k"
   },
   "source": [
    "Insert **the answers for the questions 1.1~1.5 below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kr08AArNlHU"
   },
   "outputs": [],
   "source": [
    "def log_likelihood_bernoulli(mu, target):\n",
    "    \"\"\" \n",
    "    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n",
    "\n",
    "    *** note. ***\n",
    "\n",
    "    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Bernoulli random variables p(x=1).\n",
    "    :param target: (FloatTensor) - shape: (batch_size x input_size) - Target samples (binary values).\n",
    "    :return: (FloatTensor) - shape: (batch_size,) - log-likelihood of target samples on the Bernoulli random variables.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    batch_size = mu.size(0)\n",
    "    mu = mu.view(batch_size, -1)\n",
    "    target = target.view(batch_size, -1)\n",
    "\n",
    "    # log_likelihood_bernoulli\n",
    "    # L = log (mu^tar * (1-mu)^(1-t)) = tar*log(mu) + (1-tar)log(1-mu)\n",
    "    return torch.sum(target * torch.log(mu) + (1-target) * torch.log(1-mu), dim=1)\n",
    "\n",
    "\n",
    "def log_likelihood_normal(mu, logvar, z):\n",
    "    \"\"\" \n",
    "    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n",
    "\n",
    "    *** note. ***\n",
    "\n",
    "    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Normal distributions.\n",
    "    :param logvar: (FloatTensor) - shape: (batch_size x input_size) - The log variance of Normal distributions.\n",
    "    :param z: (FloatTensor) - shape: (batch_size x input_size) - Target samples.\n",
    "    :return: (FloatTensor) - shape: (batch_size,) - log probability of the sames on the given Normal distributions.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    batch_size = mu.size(0)\n",
    "    mu = mu.view(batch_size, -1)\n",
    "    logvar = logvar.view(batch_size, -1)\n",
    "    z = z.view(batch_size, -1)\n",
    "\n",
    "    # log normal\n",
    "    # L = log (1/(sd*sqrt(2*pi))exp(-1/2((x-mu)/sd)^2)) = -log(sd*sqrt(2*pi)) -1/2((x-mu)/sd)^2)\n",
    "    # L = -log(sqrt(2*pi*var) - 1/2((x-mu)^2/var))\n",
    "    var = torch.exp(logvar)\n",
    "    return torch.sum(-torch.log((2*np.pi*var)**0.5) - (z-mu)**2/(2*var), dim=1)\n",
    "\n",
    "\n",
    "def log_mean_exp(y):\n",
    "    \"\"\" \n",
    "    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n",
    "\n",
    "    *** note. ***\n",
    "\n",
    "    :param y: (FloatTensor) - shape: (batch_size x sample_size) - Values to be evaluated for log_mean_exp. For example log proababilies\n",
    "    :return: (FloatTensor) - shape: (batch_size,) - Output for log_mean_exp.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    batch_size = y.size(0)\n",
    "    sample_size = y.size(1)\n",
    "\n",
    "    # log_mean_exp = log(1/k* sum^k(exp(y_i^k-a_i))) + a_i\n",
    "    y_max, idx = torch.max(y, dim=1)\n",
    "    y_max = y_max.reshape(-1,1) # reshape: (batch_size, )\n",
    "    return torch.log(torch.mean(torch.exp(y - y_max), dim=1, keepdim=True)) + y_max \n",
    "\n",
    "\n",
    "def kl_gaussian_gaussian_analytic(mu_q, logvar_q, mu_p, logvar_p):\n",
    "    \"\"\" \n",
    "    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n",
    "\n",
    "    *** note. ***\n",
    "\n",
    "    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n",
    "    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n",
    "    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n",
    "    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n",
    "    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n",
    "    \"\"\"\n",
    "    # init\n",
    "    batch_size = mu_q.size(0)\n",
    "    mu_q = mu_q.view(batch_size, -1)\n",
    "    logvar_q = logvar_q.view(batch_size, -1)\n",
    "    mu_p = mu_p.view(batch_size, -1)\n",
    "    logvar_p = logvar_p.view(batch_size, -1)\n",
    "\n",
    "    # kld\n",
    "    # ref: https://en.wikipedia.org/wiki/Kullbackâ€“Leibler_divergence#Multivariate_normal_distributions\n",
    "    # D_KL[q||p] = 1/2(trace(var_p ^{-1} var_q) + (mu_p - mu_q)^T var_p ^{-1} (mu_p - mu_q) - input_size + log(det_p/det_q))\n",
    "    diff_mu = mu_p - mu_q\n",
    "    \n",
    "    trace = torch.sum(torch.exp(logvar_q - logvar_p), dim=1)\n",
    "    diff_inv_diff = torch.sum(diff_mu / torch.exp(logvar_p) * diff_mu, dim=1)\n",
    "    input_size = mu_q.size(1)\n",
    "    log = torch.sum(logvar_p, dim=1) - torch.sum(logvar_q, dim=1) # shape: (batch_size, 1)\n",
    "    \n",
    "    return (trace + diff_inv_diff - input_size + log) / 2\n",
    "\n",
    "\n",
    "def kl_gaussian_gaussian_mc(mu_q, logvar_q, mu_p, logvar_p, num_samples=1):\n",
    "    \"\"\" \n",
    "    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n",
    "\n",
    "    *** note. ***\n",
    "\n",
    "    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n",
    "    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n",
    "    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n",
    "    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n",
    "    :param num_samples: (int) - shape: () - The number of sample for Monte Carlo estimate for KL-divergence\n",
    "    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n",
    "    \"\"\"\n",
    "    # init\n",
    "    batch_size = mu_q.size(0)\n",
    "    input_size = np.prod(mu_q.size()[1:])\n",
    "    mu_q = mu_q.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n",
    "    logvar_q = logvar_q.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n",
    "    mu_p = mu_p.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n",
    "    logvar_p = logvar_p.view(batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n",
    "\n",
    "    # kld\n",
    "    # define the distributions\n",
    "    q = torch.distributions.MultivariateNormal(mu_q, torch.diag_embed(torch.exp(logvar_q)))\n",
    "    p = torch.distributions.MultivariateNormal(mu_p, torch.diag_embed(torch.exp(logvar_p)))\n",
    "    z = q.sample()\n",
    "    \n",
    "    return torch.mean(q.log_prob(z) - p.log_prob(z), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3v_ld3ITRFl"
   },
   "source": [
    "Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiK4L0TdETNb"
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset_location, batch_size):\n",
    "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
    "    # start processing\n",
    "    def lines_to_np_array(lines):\n",
    "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
    "    splitdata = []\n",
    "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
    "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
    "        filepath = os.path.join(dataset_location, filename)\n",
    "        utils.download_url(URL + filename, dataset_location)\n",
    "        with open(filepath) as f:\n",
    "            lines = f.readlines()\n",
    "        x = lines_to_np_array(lines).astype('float32')\n",
    "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
    "        # pytorch data loader\n",
    "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
    "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
    "        splitdata.append(dataset_loader)\n",
    "    return splitdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZsL1gLLEVJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = get_data_loader(\"binarized_mnist\", 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PoFxey7TUFS"
   },
   "source": [
    "Define VAE network architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POBmU6UCEb4l"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(784, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 2 * latent_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        z_mean, z_logvar = self.mlp(x.view(batch_size, 784)).chunk(2, dim=-1)\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_size, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 784),\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.mlp(z) - 5.\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encode = Encoder(latent_size)\n",
    "        self.decode = Decoder(latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_logvar = self.encode(x)\n",
    "        z_sample = z_mean + torch.exp(z_logvar / 2.) * torch.randn_like(z_logvar)\n",
    "        x_mean = self.decode(z_sample)\n",
    "        return z_mean, z_logvar, x_mean\n",
    "\n",
    "    def loss(self, x, z_mean, z_logvar, x_mean):\n",
    "        ZERO = torch.zeros(z_mean.size())\n",
    "        #kl = kl_gaussian_gaussian_mc(z_mean, z_logvar, ZERO, ZERO, num_samples=1000).mean()\n",
    "        kl = kl_gaussian_gaussian_analytic(z_mean, z_logvar, ZERO, ZERO).mean()\n",
    "        recon_loss = -log_likelihood_bernoulli(\n",
    "            torch.sigmoid(x_mean.view(x.size(0), -1)),\n",
    "            x.view(x.size(0), -1),            \n",
    "        ).mean()\n",
    "        return recon_loss + kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Phg07ERvTYuh"
   },
   "source": [
    "Initialize a model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "xTxgDwZfEesO",
    "outputId": "4d0db765-9306-4b84-e66b-fe8403567623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encode): Encoder(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=300, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=300, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decode): Decoder(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=300, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=300, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(100)\n",
    "params = vae.parameters()\n",
    "optimizer = Adam(params, lr=3e-4)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oqw9SI7aTdtG"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWtQakAOEhxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-elbo:  167.93463134765625\n",
      "-elbo:  144.76071166992188\n",
      "-elbo:  130.29869079589844\n",
      "-elbo:  122.106689453125\n",
      "-elbo:  116.83917236328125\n",
      "-elbo:  113.26568603515625\n",
      "-elbo:  111.04727172851562\n",
      "-elbo:  109.50458526611328\n",
      "-elbo:  107.87423706054688\n",
      "-elbo:  107.1313247680664\n",
      "-elbo:  106.11711120605469\n",
      "-elbo:  105.00074768066406\n",
      "-elbo:  104.54178619384766\n",
      "-elbo:  103.69232940673828\n",
      "-elbo:  103.34203338623047\n",
      "-elbo:  102.83753204345703\n",
      "-elbo:  102.25534057617188\n",
      "-elbo:  101.78614044189453\n",
      "-elbo:  101.39635467529297\n",
      "-elbo:  101.4257583618164\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # train\n",
    "    for x in train:\n",
    "        optimizer.zero_grad()\n",
    "        z_mean, z_logvar, x_mean = vae(x)\n",
    "        loss = vae.loss(x, z_mean, z_logvar, x_mean)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluate ELBO on the valid dataset\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.\n",
    "        total_count = 0\n",
    "        for x in valid:\n",
    "            total_loss += vae.loss(x, *vae(x)) * x.size(0)\n",
    "            total_count += x.size(0)\n",
    "        print('-elbo: ', (total_loss / total_count).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXp5vuhDTg1J"
   },
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYfmW5TAElEO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucas/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/lucas/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/lucas/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(vae, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Iz6QX_KTizK"
   },
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hqcb8BrmEnMh"
   },
   "outputs": [],
   "source": [
    "vae = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTpoVRncTmSR"
   },
   "source": [
    "Evaluate the $\\log p_\\theta(x)$ of the model on test by using importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tc2q6dxgEsIh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log p(x): -95.62511444091797\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0.\n",
    "total_count = 0\n",
    "arr = []\n",
    "with torch.no_grad():\n",
    "    #x = next(iter(test))\n",
    "    for x in test:\n",
    "        # init\n",
    "        K = 200\n",
    "        M = x.size(0)\n",
    "\n",
    "        # Sample from the posterior\n",
    "        z_mean, z_logvar = vae.encode(x)\n",
    "        eps = torch.randn(z_mean.size(0), K, z_mean.size(1))\n",
    "        z_samples = z_mean[:, None, :] + torch.exp(z_logvar / 2.)[:, None, :] * eps # Broadcast the noise over the mean and variance\n",
    "\n",
    "        # Decode samples\n",
    "        z_samples_flat = z_samples.view(-1, z_samples.size(-1)) # Flatten out the z samples\n",
    "        x_mean_flat = vae.decode(z_samples_flat) # Push it through\n",
    "\n",
    "        # Reshape images and posterior to evaluate probabilities\n",
    "        x_flat = x[:, None].repeat(1, K, 1, 1, 1).reshape(M*K, -1)\n",
    "        z_mean_flat = z_mean[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
    "        z_logvar_flat =  z_logvar[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
    "        ZEROS = torch.zeros(z_mean_flat.size())\n",
    "\n",
    "        # Calculate all the probabilities!\n",
    "        log_p_x_z = log_likelihood_bernoulli(torch.sigmoid(x_mean_flat), x_flat).view(M, K)\n",
    "        log_q_z_x = log_likelihood_normal(z_mean_flat, z_logvar_flat, z_samples_flat).view(M, K)\n",
    "        log_p_z = log_likelihood_normal(ZEROS, ZEROS, z_samples_flat).view(M, K)\n",
    "\n",
    "        # Recombine them.\n",
    "        w = log_p_x_z + log_p_z - log_q_z_x\n",
    "        log_p = log_mean_exp(w)\n",
    "\n",
    "        # Accumulate\n",
    "        total_loss += log_p.sum()\n",
    "        total_count += M\n",
    "          \n",
    "        arr.append((total_loss / total_count).item())\n",
    "        \n",
    "print('log p(x):', (total_loss / total_count).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log p(x): -95.60469055175781\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0.\n",
    "total_count = 0\n",
    "arr = []\n",
    "with torch.no_grad():\n",
    "    #x = next(iter(test))\n",
    "    for x in test:\n",
    "        # init\n",
    "        K = 200\n",
    "        M = x.size(0)\n",
    "\n",
    "        # Sample from the posterior\n",
    "        z_mean, z_logvar = vae.encode(x)\n",
    "        eps = torch.randn(z_mean.size(0), K, z_mean.size(1))\n",
    "        z_samples = z_mean[:, None, :] + torch.exp(z_logvar / 2.)[:, None, :] * eps # Broadcast the noise over the mean and variance\n",
    "\n",
    "        # Decode samples\n",
    "        z_samples_flat = z_samples.view(-1, z_samples.size(-1)) # Flatten out the z samples\n",
    "        x_mean_flat = vae.decode(z_samples_flat) # Push it through\n",
    "\n",
    "        # Reshape images and posterior to evaluate probabilities\n",
    "        x_flat = x[:, None].repeat(1, K, 1, 1, 1).reshape(M*K, -1)\n",
    "        z_mean_flat = z_mean[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
    "        z_logvar_flat =  z_logvar[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
    "        ZEROS = torch.zeros(z_mean_flat.size())\n",
    "\n",
    "        # Calculate all the probabilities!\n",
    "        log_p_x_z = log_likelihood_bernoulli(torch.sigmoid(x_mean_flat), x_flat).view(M, K)\n",
    "        log_q_z_x = log_likelihood_normal(z_mean_flat, z_logvar_flat, z_samples_flat).view(M, K)\n",
    "        log_p_z = log_likelihood_normal(ZEROS, ZEROS, z_samples_flat).view(M, K)\n",
    "\n",
    "        # Recombine them.\n",
    "        w = log_p_x_z + log_p_z - log_q_z_x\n",
    "        log_p = log_mean_exp(w)\n",
    "\n",
    "        # Accumulate\n",
    "        total_loss += log_p.sum()\n",
    "        total_count += M\n",
    "          \n",
    "        arr.append((total_loss / total_count).item())\n",
    "        \n",
    "print('log p(x):', (total_loss / total_count).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-103.39934539794922, -105.12080383300781, -105.7254409790039, -106.2130355834961, -105.33979797363281, -106.64531707763672, -106.3676528930664, -106.39151000976562, -106.56153869628906, -106.7182388305664, -106.00627136230469, -105.41098022460938, -105.68479919433594, -105.3115463256836, -105.6065673828125, -103.22181701660156, -99.87994384765625, -96.89378356933594, -94.44324493408203, -92.26286315917969, -90.27893829345703, -88.23207092285156, -86.52072143554688, -84.87870025634766, -83.45452880859375, -82.13642883300781, -80.92396545410156, -79.7956771850586, -78.77132415771484, -78.16651916503906, -77.27571105957031, -76.4686508178711, -75.82145690917969, -76.72113800048828, -77.82655334472656, -78.76113891601562, -79.55526733398438, -80.3714599609375, -81.00475311279297, -81.79635620117188, -82.47598266601562, -83.18425750732422, -84.010498046875, -84.7567367553711, -85.31884002685547, -86.08030700683594, -86.63522338867188, -87.23941040039062, -87.79821014404297, -88.21414184570312, -88.48722076416016, -88.69462585449219, -88.95362091064453, -89.18097686767578, -89.3722915649414, -89.6334228515625, -89.78434753417969, -90.12921142578125, -90.48308563232422, -90.6999282836914, -90.89405822753906, -91.14773559570312, -91.49398803710938, -91.72765350341797, -92.00224304199219, -92.06580352783203, -92.13318634033203, -92.22573852539062, -92.24687194824219, -92.3133316040039, -92.3404541015625, -92.3998031616211, -92.36315155029297, -92.41500854492188, -92.49224853515625, -92.5467300415039, -92.58564758300781, -92.67266082763672, -92.72310638427734, -92.83246612548828, -92.96803283691406, -93.1505126953125, -93.33452606201172, -93.55651092529297, -93.7217788696289, -93.93302917480469, -94.06253051757812, -94.21023559570312, -94.3924331665039, -94.54309844970703, -94.58939361572266, -94.70233154296875, -94.83222198486328, -94.9638900756836, -95.04743957519531, -95.11531829833984, -95.14979553222656, -95.24775695800781, -95.35542297363281, -95.38838195800781, -95.4591293334961, -95.49247741699219, -95.50346374511719, -95.53791809082031, -95.54264068603516, -95.54246520996094, -95.59041595458984, -95.59966278076172, -95.65459442138672, -95.58564758300781, -95.4929428100586, -95.38246154785156, -95.27938079833984, -95.1528091430664, -95.07061767578125, -95.00750732421875, -94.9329833984375, -94.7495346069336, -94.6191635131836, -94.49327850341797, -94.32564544677734, -94.19844818115234, -94.10403442382812, -94.06868743896484, -93.98704528808594, -94.09742736816406, -94.29055786132812, -94.49723815917969, -94.67912292480469, -94.80059051513672, -95.00746154785156, -95.1891098022461, -95.33344268798828, -95.44664001464844, -95.5848617553711, -95.74165344238281, -95.8671646118164, -95.98371124267578, -96.10555267333984, -96.2667236328125, -96.29009246826172, -96.2192153930664, -96.1932601928711, -96.15314483642578, -96.11573791503906, -96.088134765625, -96.06889343261719, -96.04296112060547, -96.00565338134766, -95.92762756347656, -95.90861511230469, -95.84281158447266, -95.75617218017578, -95.72946166992188, -95.66044616699219, -95.60722351074219, -95.60469055175781]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "arr = [-103.39934539794922, -105.12080383300781, -105.7254409790039, -106.2130355834961, -105.33979797363281, -106.64531707763672, -106.3676528930664, -106.39151000976562, -106.56153869628906, -106.7182388305664, -106.00627136230469, -105.41098022460938, -105.68479919433594, -105.3115463256836, -105.6065673828125, -103.22181701660156, -99.87994384765625, -96.89378356933594, -94.44324493408203, -92.26286315917969, -90.27893829345703, -88.23207092285156, -86.52072143554688, -84.87870025634766, -83.45452880859375, -82.13642883300781, -80.92396545410156, -79.7956771850586, -78.77132415771484, -78.16651916503906, -77.27571105957031, -76.4686508178711, -75.82145690917969, -76.72113800048828, -77.82655334472656, -78.76113891601562, -79.55526733398438, -80.3714599609375, -81.00475311279297, -81.79635620117188, -82.47598266601562, -83.18425750732422, -84.010498046875, -84.7567367553711, -85.31884002685547, -86.08030700683594, -86.63522338867188, -87.23941040039062, -87.79821014404297, -88.21414184570312, -88.48722076416016, -88.69462585449219, -88.95362091064453, -89.18097686767578, -89.3722915649414, -89.6334228515625, -89.78434753417969, -90.12921142578125, -90.48308563232422, -90.6999282836914, -90.89405822753906, -91.14773559570312, -91.49398803710938, -91.72765350341797, -92.00224304199219, -92.06580352783203, -92.13318634033203, -92.22573852539062, -92.24687194824219, -92.3133316040039, -92.3404541015625, -92.3998031616211, -92.36315155029297, -92.41500854492188, -92.49224853515625, -92.5467300415039, -92.58564758300781, -92.67266082763672, -92.72310638427734, -92.83246612548828, -92.96803283691406, -93.1505126953125, -93.33452606201172, -93.55651092529297, -93.7217788696289, -93.93302917480469, -94.06253051757812, -94.21023559570312, -94.3924331665039, -94.54309844970703, -94.58939361572266, -94.70233154296875, -94.83222198486328, -94.9638900756836, -95.04743957519531, -95.11531829833984, -95.14979553222656, -95.24775695800781, -95.35542297363281, -95.38838195800781, -95.4591293334961, -95.49247741699219, -95.50346374511719, -95.53791809082031, -95.54264068603516, -95.54246520996094, -95.59041595458984, -95.59966278076172, -95.65459442138672, -95.58564758300781, -95.4929428100586, -95.38246154785156, -95.27938079833984, -95.1528091430664, -95.07061767578125, -95.00750732421875, -94.9329833984375, -94.7495346069336, -94.6191635131836, -94.49327850341797, -94.32564544677734, -94.19844818115234, -94.10403442382812, -94.06868743896484, -93.98704528808594, -94.09742736816406, -94.29055786132812, -94.49723815917969, -94.67912292480469, -94.80059051513672, -95.00746154785156, -95.1891098022461, -95.33344268798828, -95.44664001464844, -95.5848617553711, -95.74165344238281, -95.8671646118164, -95.98371124267578, -96.10555267333984, -96.2667236328125, -96.29009246826172, -96.2192153930664, -96.1932601928711, -96.15314483642578, -96.11573791503906, -96.088134765625, -96.06889343261719, -96.04296112060547, -96.00565338134766, -95.92762756347656, -95.90861511230469, -95.84281158447266, -95.75617218017578, -95.72946166992188, -95.66044616699219, -95.60722351074219, -95.60469055175781]\n",
    "epochs = np.arange(157)\n",
    "\n",
    "x = [0.00, 0.26, 1.77, 1.82, 1.9, 1.91, 1.91, 1.92, 1.92, 1.93, 1.94, 1.95, 1.95, 1.96, 1.98, 2.00, 2.00, 2.00, 2.00, 2.00]\n",
    "y = np.arange(0, 2, 0.1)\n",
    "plt.figure(figsize=(8,6)) \n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.title('log likelihood estimate evaluation')\n",
    "plt.ylabel('log(p(x))')\n",
    "plt.xlabel('number of test samples')\n",
    "#plt.figure(figsize=(12,10))\n",
    "plt.show()\n",
    "plt.savefig('log.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
